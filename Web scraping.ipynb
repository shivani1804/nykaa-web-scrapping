{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "235cd384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "061f223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to extract information from the web page\n",
    "\n",
    "def get_productName(soup):\n",
    "    try:\n",
    "        product = soup.find('span',class_='css-cmh3n9').text.strip()\n",
    "    except:\n",
    "        product=\"\"\n",
    "    return product\n",
    "\n",
    "def get_OrignalPrice(soup):\n",
    "    try:\n",
    "        orignalPrice = soup.find('span',class_='css-5pw8k6').text.strip()\n",
    "    except:\n",
    "        orignalPrice= get_DiscountPrice(soup)\n",
    "    return orignalPrice\n",
    "\n",
    "def get_DiscountPrice(soup):\n",
    "    try:\n",
    "        discountPrice = soup.find('span',class_='css-1byl9fj').text.replace('â‚¹',\"\").strip()\n",
    "    except:\n",
    "        discountPrice=\"NaN\"\n",
    "    return discountPrice\n",
    "\n",
    "def get_Rating(soup):\n",
    "    try:\n",
    "        rating = soup.find('div',class_='css-xoezkq').text.strip()\n",
    "    except:\n",
    "        rating=\"NaN\"\n",
    "    return rating\n",
    "\n",
    "def get_numRate(soup):\n",
    "    try:\n",
    "        noUserRating = soup.find('div', class_='css-xoezkq').text.strip()\n",
    "    except:\n",
    "        noUserRating = 0\n",
    "    return noUserRating\n",
    "\n",
    "\n",
    "def get_productDetails(soup):\n",
    "    try:\n",
    "        details={}\n",
    "        divElements = soup.find_all('div', class_='css-134y3ft')\n",
    "        for div in divElements:\n",
    "            pElements =div.find_all('p')\n",
    "            if len(pElements) == 2:\n",
    "                key =pElements[0].text.strip()\n",
    "                value=pElements[1].text.strip()\n",
    "                details[key] =value\n",
    "    except:\n",
    "        pass\n",
    "    return details\n",
    "\n",
    "def get_vendorDetails(soup):\n",
    "    try:\n",
    "        vendor={}\n",
    "        divElements = soup.find_all('div', class_='css-1g1kvky')\n",
    "        for div in divElements:\n",
    "            pElements =div.find_all('div')\n",
    "            if len(pElements) == 2:\n",
    "                key =pElements[0].text.strip()\n",
    "                value=pElements[1].text.strip()\n",
    "                vendor[key] =value\n",
    "    except:\n",
    "        pass\n",
    "    return vendor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fd0bbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.51881837844849\n",
      "96.26448631286621\n",
      "94.05845165252686\n",
      "101.66101956367493\n",
      "86.47212600708008\n",
      "93.08534741401672\n",
      "90.45357298851013\n",
      "53.56096410751343\n",
      "93.72577953338623\n",
      "91.31123089790344\n",
      "90.168630361557\n",
      "99.78310251235962\n",
      "89.36498856544495\n",
      "90.72087240219116\n",
      "88.96973538398743\n",
      "90.39789462089539\n",
      "86.35625910758972\n",
      "85.57643866539001\n",
      "93.19184136390686\n",
      "90.22363948822021\n",
      "89.64612793922424\n",
      "90.78181409835815\n",
      "45.65208601951599\n",
      "91.84605932235718\n",
      "89.38432598114014\n",
      "98.43163704872131\n",
      "85.32168412208557\n",
      "97.82492065429688\n",
      "90.81940484046936\n",
      "99.35384106636047\n",
      "95.40117692947388\n",
      "89.05250144004822\n",
      "98.96961331367493\n",
      "101.50494480133057\n",
      "105.36716651916504\n",
      "100.04395270347595\n",
      "93.02995896339417\n",
      "52.0618531703949\n",
      "93.54885077476501\n",
      "87.81505846977234\n",
      "77.8949019908905\n",
      "89.76693749427795\n",
      "88.76095199584961\n",
      "83.64707064628601\n",
      "94.11026668548584\n",
      "97.0020215511322\n",
      "88.37360000610352\n",
      "105.24247670173645\n",
      "90.69108867645264\n",
      "84.0130398273468\n",
      "95.51460242271423\n",
      "93.39480328559875\n",
      "50.90128207206726\n",
      "99.33986449241638\n",
      "93.00239491462708\n",
      "94.45858979225159\n",
      "87.89991116523743\n",
      "90.31345224380493\n",
      "92.25179123878479\n",
      "94.68804144859314\n",
      "88.34440660476685\n",
      "90.3450198173523\n",
      "93.6607620716095\n",
      "92.04168772697449\n",
      "89.05803990364075\n",
      "98.70108008384705\n",
      "86.03470158576965\n",
      "42.54235291481018\n",
      "95.02200627326965\n",
      "100.42257571220398\n",
      "103.22017216682434\n",
      "106.08918499946594\n",
      "85.81868433952332\n",
      "85.77402925491333\n",
      "75.1424789428711\n",
      "91.77047181129456\n",
      "91.38325381278992\n",
      "90.72983860969543\n",
      "92.0442943572998\n",
      "2279.323988199234\n",
      "83.56677412986755\n",
      "89.9032883644104\n",
      "45.04078507423401\n",
      "76.42866683006287\n",
      "88.3205053806305\n",
      "81.04207158088684\n",
      "92.3257577419281\n",
      "88.53634357452393\n",
      "89.54136490821838\n",
      "87.98610138893127\n",
      "86.32258558273315\n",
      "84.52473902702332\n",
      "87.68343043327332\n",
      "87.03071999549866\n",
      "85.53860116004944\n",
      "86.34883427619934\n",
      "89.7740387916565\n",
      "40.69856262207031\n",
      "82.62828755378723\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    \n",
    "    # Initialize a dictionary to store data\n",
    "    file ={'Product':[] , 'OrignalPrice':[] , \n",
    "           'DiscountPrice':[] ,'Rating':[] ,\n",
    "           'NumUserRating':[],'Occasion':[],\n",
    "           'Material':[],'Pattern':[],'Closure Type':[],\n",
    "           'Fit':[],'Sleeve Type':[],'Type':[],\n",
    "           'Rise Style':[],'Neckline Type':[],\n",
    "           'Sold By':[], 'Country of Origin':[] }\n",
    "    \n",
    "    # Loop through multiple pages of the website\n",
    "    for page_number in range(1,100):\n",
    "        url =f'https://www.nykaafashion.com/women/westernwear/c/3?p={page_number}'\n",
    "        \n",
    "         # Define headers to mimic a web browser\n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "        \n",
    "        try: \n",
    "            start_time =time.time()\n",
    "            # Send a GET request to the URL\n",
    "            response = requests.get(url, headers = headers)\n",
    "            soups = BeautifulSoup(response.content , 'html.parser')\n",
    "            soup = BeautifulSoup(soups.prettify() , 'html.parser')\n",
    "            \n",
    "            # Find links to individual product pages\n",
    "            links = soup.find_all(\"a\", attrs={'class':'css-1t10dtm'})\n",
    "            links_list=[]\n",
    "            for l in links:\n",
    "                urlLink ='https://www.nykaafashion.com/'+l.get('href')\n",
    "                links_list.append(urlLink)\n",
    "\n",
    "            # Loop through each product page and extract information\n",
    "            for link in links_list:\n",
    "                source = requests.get(link,headers = headers)\n",
    "\n",
    "                soups = BeautifulSoup(source.content , 'html.parser')\n",
    "                new_soup = BeautifulSoup(soups.prettify() , 'html.parser')\n",
    "\n",
    "                file['Product'].append(get_productName(new_soup))\n",
    "                file['OrignalPrice'].append(get_OrignalPrice(new_soup))\n",
    "                file['DiscountPrice'].append(get_DiscountPrice(new_soup))\n",
    "                file['Rating'].append(get_Rating(new_soup))\n",
    "                file['NumUserRating'].append(get_numRate(new_soup))\n",
    "\n",
    "                product_details =get_productDetails(new_soup)\n",
    "                file['Occasion'].append(product_details.get('Occasion', 'N/A'))\n",
    "                file['Material'].append(product_details.get('Material', 'N/A'))\n",
    "                file['Pattern'].append(product_details.get('Pattern', 'N/A'))\n",
    "                file['Closure Type'].append(product_details.get('Closure Type', 'N/A'))\n",
    "                file['Fit'].append(product_details.get('Fit', 'N/A'))\n",
    "                file['Sleeve Type'].append(product_details.get('Sleeve Type', 'N/A'))\n",
    "                file['Type'].append(product_details.get('Type', 'N/A'))\n",
    "                file['Rise Style'].append(product_details.get('Rise Style', 'N/A'))\n",
    "                file['Neckline Type'].append(product_details.get('Neckline Type', 'N/A'))\n",
    "\n",
    "\n",
    "                vendor_details =get_vendorDetails(new_soup)\n",
    "                file['Sold By'].append(vendor_details.get('Sold By', 'N/A'))\n",
    "                file['Country of Origin'].append(vendor_details.get('Country of Origin', 'N/A'))\n",
    "\n",
    "                # Sleep for a while to avoid overloading the server\n",
    "                time.sleep(1)\n",
    "#             print(time.time()-start_time)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'Error: {page_number} , str{e}')\n",
    "    \n",
    "    # Create a DataFrame from the dictionary and save it to a CSV file        \n",
    "    df =pd.DataFrame(data =file)\n",
    "    df.to_csv(r\"C:\\Users\\Dell\\Desktop\\Shivani_jupyter\\NykaaScrap.csv\",sep =',',encoding ='UTF8')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
